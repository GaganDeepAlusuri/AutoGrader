{
    "SID": [
        "U101",
        "U102",
        "U103",
        "U104"
    ],
    "S_NAME": [
        "JohnCena",
        "TheRock",
        "Lucifer",
        "Selena"
    ],
    "RAW_FILE": [
        "D:\\AutoGrader\\src\\autograder\\submissions\\U101_JohnCena.ipynb",
        "D:\\AutoGrader\\src\\autograder\\submissions\\U102_TheRock.ipynb",
        "D:\\AutoGrader\\src\\autograder\\submissions\\U103_Lucifer.py.py",
        "D:\\AutoGrader\\src\\autograder\\submissions\\U104_Selena.py.py"
    ],
    "PROCESSED_FILE": [
        "import os\nimport openai\nfrom dotenv import load_dotenv, find_dotenv\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nfrom openai import OpenAI\n\nmodel = \"gpt-3.5-turbo\"\nclient = OpenAI()\n\n\ndef get_completion_from_messages(\n    messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500\n):\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,  # this is the degree of randomness of the model's output\n        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n    )\n    return response.choices[0].message.content\n\n# #### Classify customer queries to handle different cases\ndelimiter = \"####\"\nsystem_message = f\"\"\"\nYou will be provided with customer service queries. \\\nThe customer service query will be delimited with \\\n{delimiter} characters.\nClassify each query into a primary category \\\nand a secondary category. \nProvide your output in json format with the \\\nkeys: primary and secondary.\n\nPrimary categories: Billing, Technical Support, \\\nAccount Management, or General Inquiry.\n\nBilling secondary categories:\nUnsubscribe or upgrade\nAdd a payment method\nExplanation for charge\nDispute a charge\n\nTechnical Support secondary categories:\nGeneral troubleshooting\nDevice compatibility\nSoftware updates\n\nAccount Management secondary categories:\nPassword reset\nUpdate personal information\nClose account\nAccount security\n\nGeneral Inquiry secondary categories:\nProduct information\nPricing\nFeedback\nSpeak to a human\n\n\"\"\"\nuser_message = f\"\"\"\\\nI want you to delete my profile and all of my user data\"\"\"\nmessages = [\n    {\"role\": \"system\", \"content\": system_message},\n    {\"role\": \"user\", \"content\": f\"{delimiter}{user_message}{delimiter}\"},\n]\nresponse = get_completion_from_messages(messages)\nprint(response)\n\nuser_message = f\"\"\"\\\nTell me more about your flat screen tvs\"\"\"\nmessages = [\n    {\"role\": \"system\", \"content\": system_message},\n    {\"role\": \"user\", \"content\": f\"{delimiter}{user_message}{delimiter}\"},\n]\nresponse = get_completion_from_messages(messages)\nprint(response)\n\n",
        "import os\nimport openai\nfrom dotenv import load_dotenv, find_dotenv\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nfrom openai import OpenAI\n\nmodel = \"gpt-3.5-turbo\"\nclient = OpenAI()\n\n\ndef get_completion_from_messages(\n    messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500\n):\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,  # this is the degree of randomness of the model's output\n        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n    )\n    return response.choices[0].message.content\n\n# #### Classify customer queries to handle different cases\ndelimiter = \"####\"\nsystem_message = f\"\"\"\nYou will be provided with customer service queries. \\\nThe customer service query will be delimited with \\\n{delimiter} characters.\nClassify each query into a primary category \\\nand a secondary category. \nProvide your output in json format with the \\\nkeys: primary and secondary.\n\nPrimary categories: Billing, Technical Support, \\\nAccount Management, or General Inquiry.\n\nBilling secondary categories:\nUnsubscribe or upgrade\nAdd a payment method\nExplanation for charge\nDispute a charge\n\nTechnical Support secondary categories:\nGeneral troubleshooting\nDevice compatibility\nSoftware updates\n\nAccount Management secondary categories:\nPassword reset\nUpdate personal information\nClose account\nAccount security\n\nGeneral Inquiry secondary categories:\nProduct information\nPricing\nFeedback\nSpeak to a human\n\n\"\"\"\nuser_message = f\"\"\"\\\nI want you to delete my profile and all of my user data\"\"\"\nmessages = [\n    {\"role\": \"system\", \"content\": system_message},\n    {\"role\": \"user\", \"content\": f\"{delimiter}{user_message}{delimiter}\"},\n]\nresponse = get_completion_from_messages(messages)\nprint(response)\n\nuser_message = f\"\"\"\\\nTell me more about your flat screen tvs\"\"\"\nmessages = [\n    {\"role\": \"system\", \"content\": system_message},\n    {\"role\": \"user\", \"content\": f\"{delimiter}{user_message}{delimiter}\"},\n]\nresponse = get_completion_from_messages(messages)\nprint(response)\n\n",
        "\n# Long Short-Term Memory Network for Time Series Prediction\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.optimizers import Adam\n\n# Generate synthetic time series data\ndef generate_time_series(batch_size, n_steps):\n    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n    time = np.linspace(0, 1, n_steps)\n    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  # Wave 1\n    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # Wave 2\n    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # Noise\n    return series[..., np.newaxis].astype(np.float32)\n\n# Prepare the data\nn_steps = 50\nseries = generate_time_series(10000, n_steps + 1)\nX_train, y_train = series[:7000, :n_steps], series[:7000, -1]\nX_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\nX_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n\n# Define the LSTM model\nmodel = Sequential([\n    LSTM(50, return_sequences=True, input_shape=[None, 1]),\n    LSTM(50),\n    Dense(1)\n])\n\n# Compile and train the model\nmodel.compile(optimizer=Adam(lr=0.01), loss='mse')\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n\n# Evaluate the model\nmse_test = model.evaluate(X_test, y_test)\nprint(f\"Test MSE: {mse_test}\")\n\n# Plot some predictions\ndef plot_series(series, y=None, y_pred=None, x_label='$t$', y_label='$x(t)$'):\n    plt.plot(series, \".-\")\n    if y is not None:\n        plt.plot(n_steps, y, \"bx\", markersize=10)\n    if y_pred is not None:\n        plt.plot(n_steps, y_pred, \"ro\")\n    plt.grid(True)\n    if x_label:\n        plt.xlabel(x_label, fontsize=16)\n    if y_label:\n        plt.ylabel(y_label, fontsize=16, rotation=0)\n    plt.hlines(0, 0, 100, linewidth=1)\n    plt.axis([0, n_steps + 1, -1, 1])\n\nfig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))\nfor col in range(3):\n    plt.sca(axes[col])\n    plot_series(X_valid[col, :, 0], y_valid[col, 0],\n                model.predict(X_valid[col:col+1])[0, 0],\n                x_label=(\"$t$\" if col==0 else None),\n                y_label=(\"$x(t)$\" if col==0 else None))\nplt.show()\n",
        "\n# Convolutional Neural Network for Image Classification\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\n# Load and prepare the CIFAR-10 dataset\n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n# Define the CNN model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\nprint(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
    ],
    "PERCENTAGE_GRADE": [
        73.212214925303,
        93.73434648319255,
        88.30498985242815,
        84.01261005776098
    ],
    "COMMENTS": [
        "Random comment for Student ID: U101",
        "Random comment for Student ID: U102",
        "Random comment for Student ID: U103",
        "Random comment for Student ID: U104"
    ]
}